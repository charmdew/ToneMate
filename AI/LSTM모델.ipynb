{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# pip install librosa\n","# pip install keras\n","# pip install tensorflow\n","# pip install os"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":350,"status":"ok","timestamp":1678682363382,"user":{"displayName":"박정희[서울_ 6반_ A604]팀원","userId":"17919197066029500351"},"user_tz":-540},"id":"XdEP3n74AnWJ"},"outputs":[],"source":["import os\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","\n","import module.lstm as LSTM_MODEL\n","import module.preprocess as PROCESSING"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["encoder = LabelEncoder()\n","FEATURES = \"MFCC20_ALL\"\n","ROOT = \"D:/DATA\"\n","SR = 16000\n","TARGET_EPOCH = 50\n","PLUS_EPOCH = 50\n","\n","\n","TRAIN_PATH = f\"{ROOT}/train\"\n","VAL_PATH = f\"{ROOT}/val\"\n","TENSER_PATH = f\"{ROOT}/tensor/{FEATURES}\"\n","CHECKPOINT_PATH = f\"{ROOT}/checkpoint\"\n","CHECK_POINT_FILE = f\"{FEATURES}/checkpoint{TARGET_EPOCH}.h5\"\n","REPLACE_FILE = f\"{FEATURES}/checkpoint{(TARGET_EPOCH+PLUS_EPOCH)}.h5\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#wav파일들을 npy파일들로 변환하기\n","# X, y = PROCESSING.createDATA(\"D:/ToneMate_wav\",SR,20,True,True,True,True,True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# npy모두 합쳐서 학습데이터 생성하기\n","X = []\n","y = []\n","for root, dirs, files in os.walk(\"D:/ToneMate_numpy\"):\n","    for file in files:\n","        if file.endswith(\".npy\"):\n","            label = file.split(\" - \")\n","            singer = label[0]\n","            title = label[1][:-4]\n","            path = os.path.join(root, file) \n","            data = np.load(path)\n","            if(data.shape[0]==36 and data.shape[1]==3000):\n","                X.append(data)\n","                y.append(singer)\n","X = np.stack(X)\n","y = np.array(y)\n","if not os.path.exists(TENSER_PATH):\n","    os.makedirs(TENSER_PATH)\n","\n","np.save(f'{TENSER_PATH}/X.npy', X)\n","np.save(f'{TENSER_PATH}/y.npy', y)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X, y = np.load(f'{TENSER_PATH}/X.npy'), np.load(f'{TENSER_PATH}/y.npy')\n","X = np.transpose(X, (0, 2, 1))\n","encoder = encoder.fit(y)\n","X_train, X_valid, y_train, y_valid = train_test_split(X, encoder.transform(y), test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":1039,"status":"error","timestamp":1678683649636,"user":{"displayName":"박정희[서울_ 6반_ A604]팀원","userId":"17919197066029500351"},"user_tz":-540},"id":"CV0F1lEjA8NZ","outputId":"169af07d-139b-4957-ca79-ed2db1b787d7"},"outputs":[],"source":["model = LSTM_MODEL.create_lstm_model(len(encoder.classes_),sr = SR,feature_size=X.shape[2])\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","checkpoint_callback = LSTM_MODEL.Checkpoint(f\"{CHECKPOINT_PATH}/{CHECK_POINT_FILE}\")\n","\n","\n","if os.path.isfile(f\"{CHECKPOINT_PATH}/{CHECK_POINT_FILE}\"):\n","    model.load_weights(f\"{CHECKPOINT_PATH}/{CHECK_POINT_FILE}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.fit(X_train, to_categorical(y_train,num_classes=len(encoder.classes_)), epochs= (TARGET_EPOCH+PLUS_EPOCH), validation_data=(X_valid, to_categorical(y_valid,num_classes=len(encoder.classes_))), callbacks=[checkpoint_callback], initial_epoch=TARGET_EPOCH)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_wav = PROCESSING.load_wav_file(f\"{ROOT}/sample/윤하.wav\")\n","test_wav = PROCESSING.preprocess_features([test_wav])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pred = model.predict(test_wav)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pred"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pred = model.predict(test_wav)\n","top_5 = np.argsort(pred, axis=1)[:, -5:]\n","top_5_labels = encoder.inverse_transform(top_5.T.ravel())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["top_5_labels"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pred"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPpGMfcfPDp4HDDzqJ8ps/W","mount_file_id":"1_bkXPhS_naITQMrL-bxV2HURkeuDjXST","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
