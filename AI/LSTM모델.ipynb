{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# pip install librosa\n","# pip install keras\n","# pip install tensorflow\n","# pip install os"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":350,"status":"ok","timestamp":1678682363382,"user":{"displayName":"박정희[서울_ 6반_ A604]팀원","userId":"17919197066029500351"},"user_tz":-540},"id":"XdEP3n74AnWJ"},"outputs":[],"source":["import os\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from keras.models import load_model\n","\n","import module.lstm as LSTM_MODEL\n","import module.preprocess as PROCESSING"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["encoder = LabelEncoder()\n","FEATURES = \"MFCC20_ALL\"\n","ROOT = \"D:/DATA\"\n","SR = 16000\n","TARGET_EPOCH = 0\n","PLUS_EPOCH = 10\n","\n","\n","TRAIN_PATH = f\"{ROOT}/train\"\n","VAL_PATH = f\"{ROOT}/val\"\n","TENSER_PATH = f\"{ROOT}/tensor/{FEATURES}\"\n","CHECKPOINT_PATH = f\"{ROOT}/checkpoint\"\n","CHECK_POINT_FILE = f\"{FEATURES}/checkpoint{TARGET_EPOCH}.h5\"\n","REPLACE_FILE = f\"{FEATURES}/checkpoint{(TARGET_EPOCH+PLUS_EPOCH)}.h5\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#wav파일들을 npy파일들로 변환하기\n","# X, y = PROCESSING.createDATA(\"D:/ToneMate_wav\",SR,20,True,True,True,True,True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# npy모두 합쳐서 학습데이터 생성하기\n","X = []\n","y = []\n","for root, dirs, files in os.walk(\"D:/ToneMate_numpy\"):\n","    for file in files:\n","        if file.endswith(\".npy\"):\n","            label = file.split(\" - \")\n","            singer = label[0]\n","            title = label[1][:-4]\n","            path = os.path.join(root, file) \n","            data = np.load(path)\n","            if(data.shape[0]==36 and data.shape[1]==3000):\n","                X.append(data)\n","                y.append(singer)\n","X = np.stack(X)\n","y = np.array(y)\n","if not os.path.exists(TENSER_PATH):\n","    os.makedirs(TENSER_PATH)\n","\n","np.save(f'{TENSER_PATH}/X.npy', X)\n","np.save(f'{TENSER_PATH}/y.npy', y)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X, y = np.load(f'{TENSER_PATH}/X.npy'), np.load(f'{TENSER_PATH}/y.npy')\n","X = np.transpose(X, (0, 2, 1))\n","encoder = encoder.fit(y)\n","X_train, X_valid, y_train, y_valid = train_test_split(X, encoder.transform(y), test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":1039,"status":"error","timestamp":1678683649636,"user":{"displayName":"박정희[서울_ 6반_ A604]팀원","userId":"17919197066029500351"},"user_tz":-540},"id":"CV0F1lEjA8NZ","outputId":"169af07d-139b-4957-ca79-ed2db1b787d7"},"outputs":[],"source":["model = LSTM_MODEL.create_lstm_model(len(encoder.classes_),sr = SR,feature_size=X.shape[2])\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","checkpoint_callback = LSTM_MODEL.Checkpoint(f\"{CHECKPOINT_PATH}/{CHECK_POINT_FILE}\")\n","\n","\n","if os.path.isfile(f\"{CHECKPOINT_PATH}/{CHECK_POINT_FILE}\"):\n","    model = load_model(f\"{CHECKPOINT_PATH}/{CHECK_POINT_FILE}\")\n","    #model.load_weights(f\"{CHECKPOINT_PATH}/{CHECK_POINT_FILE}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if not os.path.exists(f\"{CHECKPOINT_PATH}/{FEATURES}\"):\n","    os.makedirs(f\"{CHECKPOINT_PATH}/{FEATURES}\")\n","\n","model.fit(X_train, to_categorical(y_train,num_classes=len(encoder.classes_)), epochs= (TARGET_EPOCH+PLUS_EPOCH), validation_data=(X_valid, to_categorical(y_valid,num_classes=len(encoder.classes_))), callbacks=[checkpoint_callback], initial_epoch=TARGET_EPOCH)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# pred = model.predict(test_wav)\n","# top_5 = np.argsort(pred, axis=1)[:, -5:]\n","# top_5_labels = encoder.inverse_transform(top_5.T.ravel())"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["YB : A Cactus\n","YB : A Flying Butterfly\n","ZionT : 5월의 밤 (May)\n","ZionT : Comedian\n","ZionT : Eat\n"]}],"source":["import os\n","import numpy as np\n","singer_g = []\n","title_g = []\n","mean_g = []\n","var_g = []\n","NUMPY_PATH = f\"C:/Users/wjdgm/Desktop/SAMPLE\"\n","\n","for root, dirs, files in os.walk(NUMPY_PATH):\n","    for file in files:\n","        if file.endswith(\".npy\"):\n","            label = file.split(\" - \")\n","            singer = label[0]\n","            title = label[1][:-4]\n","            path = os.path.join(root, file) \n","            data = np.load(path)\n","            data_mean = [round(attr, 5) for attr in data.mean(axis=1)]\n","            data_var = [round(attr, 5) for attr in data.var(axis=1)]\n","\n","            singer_g.append(singer)\n","            title_g.append(title)\n","            mean_g.append(data_mean)\n","            var_g.append(data_var)\n","            print(singer,\":\",title)\n","            \n","mean_g = np.array(mean_g)\n","var_g = np.array(var_g)\n","\n","\n","\n","#표준화\n","mean_g_mean_by_col = mean_g.mean(axis=0)\n","mean_g_std_by_col = mean_g.std(axis=0)\n","var_g_mean_by_col = var_g.mean(axis=0)\n","var_g_std_by_col = var_g.std(axis=0)\n","\n","mean_g = (mean_g-mean_g_mean_by_col)/mean_g_std_by_col\n","var_g = (var_g-var_g_mean_by_col)/var_g_std_by_col"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["mean_g = (mean_g-mean_g_mean_by_col)/mean_g_std_by_col\n","var_g = (var_g-var_g_mean_by_col)/var_g_std_by_col"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPpGMfcfPDp4HDDzqJ8ps/W","mount_file_id":"1_bkXPhS_naITQMrL-bxV2HURkeuDjXST","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
